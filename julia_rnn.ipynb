{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0020326260805686542\n",
      " -0.011779828267081568]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2x1 Array{Float64,2}:\n",
       " 0.0\n",
       " 0.0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workspace()\n",
    "type RNN\n",
    "    Whh   # Initialize these with random values from normal distribution,\n",
    "    Wxh   # scaled way down.\n",
    "    Why\n",
    "    bh\n",
    "    by\n",
    "\n",
    "    mWhh   # Initialize these with random values from normal distribution,\n",
    "    mWxh   # scaled way down.\n",
    "    mWhy\n",
    "    mbh\n",
    "    mby\n",
    "\n",
    "    # TODO: remove h.\n",
    "    h     # Not a variable, but still associated with the RNN.\n",
    "    hidden_length\n",
    "    \n",
    "    function RNN(in_dim::Integer, hidden_dim::Integer, out_dim::Integer)\n",
    "        # Initialize the Weights/Biases variables\n",
    "        Whh = randn(hidden_dim, hidden_dim)*0.01\n",
    "        Wxh = randn(hidden_dim, in_dim)*0.01\n",
    "        Why = randn(out_dim, hidden_dim)*0.01\n",
    "        bh = zeros(hidden_dim, 1)\n",
    "        by = zeros(out_dim, 1)\n",
    "        \n",
    "        # Initialize the memory variables\n",
    "        mWhh, mWxh, mWhy, mbh, mby = zeros(Whh),zeros(Wxh), zeros(Why), zeros(bh), zeros(by)\n",
    "        \n",
    "        h = zeros(bh)\n",
    "        #hidden_length = randn(hidden_dim, 1),\n",
    "        hidden_length = hidden_dim\n",
    "\n",
    "        new(Whh, Wxh, Why, bh, by, mWhh, mWxh, mWhy, mbh, mby, h, hidden_length)\n",
    "    end\n",
    "end\n",
    "r = RNN(1,2,1)\n",
    "println(r.Wxh)\n",
    "r.h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3x1 Array{Float64,2}:\n",
       "  1.0\n",
       " -5.0\n",
       "  5.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function clip_values(deltas_matrix, max_threshold::Float64, min_threshold::Float64)\n",
    "    deltas_matrix = max(deltas_matrix, min_threshold)\n",
    "    deltas_matrix = min(deltas_matrix, max_threshold)\n",
    "    return deltas_matrix\n",
    "end\n",
    "clip_values([1.0 -11.0 6.0]', 5.0, -5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1,(4,2.0f0))\n",
      "1 2 3 4 "
     ]
    },
    {
     "data": {
      "text/plain": [
       "2x1 Array{Float64,2}:\n",
       " 0.0\n",
       " 0.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Dict{Int32,Float32}()\n",
    "x[4] = 2.0\n",
    "x\n",
    "for i in enumerate(x)\n",
    "    println(i)\n",
    "end\n",
    "for i in range(1,4)\n",
    "    print(i) ; print(' ')\n",
    "end\n",
    "\n",
    "zeros([2 232 2; 2  2 1])\n",
    "r.bh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ys:\n",
      "[0.33330951534736897\n",
      " 0.3333406406371714\n",
      " 0.3333498440154596]\n",
      "[0.33333748689492954\n",
      " 0.33332865248686105\n",
      " 0.33333386061820935]\n",
      "[0.3333096100905018\n",
      " 0.33334065387341205\n",
      " 0.33334973603608614]\n",
      "h:\n",
      "[0.0031506157848285982\n",
      " 0.0012353992743882975\n",
      " -0.009110897172611366\n",
      " -0.0004064513621215561]\n"
     ]
    }
   ],
   "source": [
    "function forward_pass(r::RNN, in_h, x)\n",
    "    local Wxh = r.Wxh\n",
    "    local Whh = r.Whh\n",
    "    local Why = r.Why\n",
    "    local bh = r.bh\n",
    "    local by = r.by\n",
    "\n",
    "    # Calculate the new h.\n",
    "    new_h = tanh(Wxh*x + Whh*in_h + bh)     # 3x1\n",
    "    #println(\"new_h:$new_h\")\n",
    "\n",
    "    y = Why*new_h + by      # 2x1\n",
    "    #println(\"y:$y\")\n",
    "\n",
    "    # exp(y) conveniently eliminates negative values from tanh.\n",
    "    exp_y = exp(y)     # 2x1 (pointwise)\n",
    "    \n",
    "    y_norm = exp_y ./ sum(exp(y)) # 2x1 Element wise division \n",
    "    #println(\"y_norm: $y_norm\")\n",
    "\n",
    "    return y_norm, y, new_h\n",
    "end\n",
    "r1 = RNN(2,4,3)\n",
    "r1.h = [0 0 0 0.]'\n",
    "y1, _, r1.h = forward_pass(r1, r1.h, [1.0 0]')\n",
    "y2, _, r1.h = forward_pass(r1, r1.h, [0.0 0.1]')\n",
    "y3, _, r1.h = forward_pass(r1, r1.h, [1.0 0.]')\n",
    "println(\"ys:\\n$y1\\n$y2\\n$y3\")\n",
    "println(\"h:\\n\",r1.h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "3\n",
      "2\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "ts=[1,2,3,4]\n",
    "for i in length(ts):-1:1\n",
    "    println(i)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparamaters\n",
    "hidden_size = 100\n",
    "learning_rate = 1e-1\n",
    "seq_length = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\n",
      "[1.3988750128749587],\n",
      "\n",
      "[-0.02348709404610685 0.15845008784877856\n",
      " -0.029956754210863596 0.15314729364197688\n",
      " -0.02401725804279269 0.12098114381203691],\n",
      "\n",
      "[0.08011354615577733 0.052773611291928826 0.06853660930090805\n",
      " 0.07453013601361681 0.049556316201140885 0.06043836265216451\n",
      " 0.058735290825127406 0.03907731268820138 0.04746229284518379],\n",
      "\n",
      "[0.02188565806931217 -0.08201489754933375 -0.12198683957866582\n",
      " -0.021885658069312197 0.08201489754933372 0.1219868395786658],\n",
      "\n",
      "[0.1349629938026717\n",
      " 0.12319053943111329\n",
      " 0.09696388576924422],\n",
      "\n",
      "[-0.20382526255910166\n",
      " 0.2038252625591016])\n",
      "\n",
      "[0.3344883118838543\n",
      " 0.37630407100318514\n",
      " 0.5673596773818216]\n"
     ]
    }
   ],
   "source": [
    "function forward_pass_backpropogate(r::RNN, xs, ts)\n",
    "    \"\"\"r - an RNN.\n",
    "    x - The batch of input vectors: a tuple of vectors.\n",
    "    t - The batch of \"truth\" vectors: a tuple of vectors of same count as xs.\"\"\"\n",
    "\n",
    "    #Forward Pass\n",
    "    hs, ys, ps = Dict(), Dict(), Dict()\n",
    "    hs[0] = r.h\n",
    "    local Wxh = r.Wxh\n",
    "    local Whh = r.Whh\n",
    "    local Why = r.Why\n",
    "    local bh = r.bh\n",
    "    local by = r.by\n",
    "\n",
    "    out_delta_max_threshold = 5.0   # Tweakable.\n",
    "    out_delta_min_threshold = -5.0   # Tweakable.\n",
    "\n",
    "    cost = 0\n",
    "    \n",
    "    for i in 1:length(ts)\n",
    "        local h = hs[i-1]\n",
    "        local x = xs[i]\n",
    "        local t = ts[i]\n",
    "\n",
    "        ps[i], ys[i], hs[i] = forward_pass(r, h, x)\n",
    "\n",
    "        # Multiply by t-inverse, to select the value from log(ps[i]) which corresponds to the truth.\n",
    "        cost += -t' * log(ps[i])  # 1x1 (scalar-ish) (log is pointwise).\n",
    "        #println(\"cost:$cost\")\n",
    "    end\n",
    "\n",
    "    # ----------  Now# go back down\n",
    "\n",
    "    \n",
    "    dWxh = zeros(r.Wxh)\n",
    "    dWhh = zeros(r.Whh)\n",
    "    dWhy = zeros(r.Why)\n",
    "    dbh  = zeros(r.bh)\n",
    "    dby  = zeros(r.by)\n",
    "    \n",
    "    #dhnext = zeros(r.h)\n",
    "    ∂cost_∂hnext = zeros(r.h)\n",
    "    for i in length(ts):-1:1\n",
    "\n",
    "        # Copied from Karpathy. I don't know what these two lines mean.\n",
    "        #dy = ps[i]\n",
    "        #dy -= ts[i] # backprop into y\n",
    "        #dWhy += dy * hs[i]'\n",
    "        #dby += dy\n",
    "        #dh = Why' * dy + dhnext # backprop into h\n",
    "        #dhraw = (1 - hs[i] .* hs[i]) .* dh # backprop through tanh nonlinearity\n",
    "        #dbh += dhraw\n",
    "        #dWxh += dhraw * xs[i]'\n",
    "        #dWhh += dhraw * hs[i-1]'\n",
    "        #dhnext = Whh' * dhraw\n",
    "        \n",
    "        \n",
    "        ∂cost_∂y = ps[i]\n",
    "        ∂cost_∂y -= ts[i] # backprop into y\n",
    " \n",
    "        ∂cost_∂Why = ∂cost_∂y * hs[i]'  # 2x3\n",
    "        ∂cost_∂by = ∂cost_∂y            # 2x1\n",
    " \n",
    "        ∂cost_∂h = Why' * ∂cost_∂y  +  ∂cost_∂hnext   # 3x1\n",
    "        dhraw = (1 - hs[i] .* hs[i]) .* ∂cost_∂h    # \"backprop through tanh nonlinearity\"\n",
    " \n",
    "        ∂cost_∂bh = dhraw  # 3x1    # noop\n",
    " \n",
    "        ∂cost_∂Whh = dhraw * hs[i-1]'   # 3x3\n",
    "        ∂cost_∂Wxh = dhraw * xs[i]'   # 3x2\n",
    " \n",
    "        ∂cost_∂hnext = Whh' * dhraw  # 3x1\n",
    " \n",
    "        # Update the final derivatives\n",
    " \n",
    "        dWxh += ∂cost_∂Wxh\n",
    "        dWhh += ∂cost_∂Whh\n",
    "        dWhy += ∂cost_∂Why\n",
    "        dbh  += ∂cost_∂bh\n",
    "        dby  += ∂cost_∂by\n",
    "\n",
    "\n",
    "        #println(\"∂cost_∂Wxh:$∂cost_∂Wxh\")\n",
    "    end\n",
    "\n",
    "    # Clip deltas to mitigate exploding gradients.\n",
    "    dWxh = clip_values(dWxh, out_delta_max_threshold, out_delta_min_threshold) \n",
    "    dWhh = clip_values(dWhh, out_delta_max_threshold, out_delta_min_threshold)\n",
    "    dWhy = clip_values(dWhy, out_delta_max_threshold, out_delta_min_threshold)\n",
    "    dbh = clip_values(dbh, out_delta_max_threshold, out_delta_min_threshold)\n",
    "    dby = clip_values(dby, out_delta_max_threshold, out_delta_min_threshold)\n",
    "     \n",
    "    # Update the hidden state from this run.\n",
    "    r.h = hs[length(ts)]\n",
    "\n",
    "    return cost, dWxh, dWhh, dWhy, dbh, dby \n",
    "\n",
    "end\n",
    "\n",
    "r = RNN(2,3,2)\n",
    "r.Wxh = [.5 .2 ; 0.1 0.1 ; 0.2 0.2]\n",
    "r.Whh = [.1 .1 .1 ; .2 .2 .2 ; 0.3 0.3 .3]\n",
    "r.Why = [.4 .5 .6; .7 .8 .9 ]\n",
    "r.h = [0.4 .2 0.8]'\n",
    "println(forward_pass_backpropogate(r, ([1 0]', [0 1]'), ([0 1]', [1 0]')))\n",
    "println(\"\\n\",r.h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2x1 Array{Float64,2}:\n",
       " 0.0\n",
       " 1.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs = ([0. 1.]', [0. 1.]')\n",
    "xs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3x1 Array{Float64,2}:\n",
       "  1.0\n",
       " -5.0\n",
       "  5.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([1.0 -11.0 5.0]', -5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "big"
     ]
    }
   ],
   "source": [
    "test_r = RNN(5,20,6)\n",
    "print(\"big\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing the print statements."
     ]
    }
   ],
   "source": [
    "forward_pass_backpropogate(test_r, ([1 10 1 3 2]',), ([2 1. 8 0.3 2 0.1]',))\n",
    "print(\"Testing the print statements.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Training!\n",
    "---------\n",
    "Now let's do the training!\n",
    "\n",
    "Concept:\n",
    "\n",
    "Calculate the gradient of the Cost with respect to each of the weights, i.e. the partial derivates $\\partial$Cost / $\\partial$Weight for each weight.\n",
    "\n",
    "This gradient represents how much the Cost would change if we update the weights a tiny bit. So we subtract the gradient from the weight to decrease the Cost!\n",
    "\n",
    "Note: We don't even care what $y$ is, we only use it to calculate the gradient for a given set of weights. So that information can stay in the backpropogate function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.8513927492820152][0.5499489269489144\n",
      " 0.32445312710513785\n",
      " 0.5042017549258068]\n",
      "[2.7732563220837685][0.2733504302372906\n",
      " -0.1218558122595025\n",
      " -0.03313777320467589]\n",
      "[0.3673099058722714 0.10641030522686429\n",
      " -0.026636732258434413 0.006942351574688553\n",
      " 0.06798023469772287 0.11654742554190307][0.014194231453489218 0.02240190796108634 0.015019502381031684\n",
      " 0.11765274426740126 0.12166334880633656 0.11498598332296982\n",
      " 0.22201671040103732 0.22457719522088102 0.2173526964776151][0.4753469640869792 0.5827236545826828 0.6514414354375764\n",
      " 0.6246530359130209 0.7172763454173171 0.8485585645624236][-0.11227657394104021\n",
      " -0.11147721367622182\n",
      " -0.11101694366027448][0.021547450149868995\n",
      " -0.021547450149868946]\n"
     ]
    }
   ],
   "source": [
    "function update(r, xs, ts)\n",
    "    \"\"\"r - RNN, xs - a batch of inputs, ts - a batch of truths (as one-hot nx1 matrices)\"\"\"\n",
    "    loss, ∂cost_∂Wxh, ∂cost_∂Whh, ∂cost_∂Why, ∂cost_∂bh, ∂cost_∂by = forward_pass_backpropogate(r,xs,ts)\n",
    "    \n",
    "    # adagrad update (Gradient Descent)\n",
    "    r.mWxh += ∂cost_∂Wxh .^ 2\n",
    "    r.mWhh += ∂cost_∂Whh .^ 2\n",
    "    r.mWhy += ∂cost_∂Why .^ 2\n",
    "    r.mbh += ∂cost_∂bh .^ 2\n",
    "    r.mby += ∂cost_∂by .^ 2\n",
    "    \n",
    "    r.Wxh -= learning_rate * ∂cost_∂Wxh  ./ sqrt(r.mWxh + 1e-8)\n",
    "    r.Whh -= learning_rate * ∂cost_∂Whh  ./ sqrt(r.mWhh + 1e-8)\n",
    "    r.Why -= learning_rate * ∂cost_∂Why  ./ sqrt(r.mWhy + 1e-8)\n",
    "    r.bh -= learning_rate * ∂cost_∂bh    ./ sqrt(r.mbh + 1e-8)\n",
    "    r.by -= learning_rate * ∂cost_∂by    ./ sqrt(r.mby + 1e-8)\n",
    "    \n",
    "    return loss\n",
    "end\n",
    "\n",
    "r = RNN(2,3,2)\n",
    "r.Wxh = [.5 .2 ; 0.1 0.1 ; 0.2 0.2]\n",
    "r.Whh = [.1 .1 .1 ; .2 .2 .2 ; 0.3 0.3 .3]\n",
    "r.Why = [.4 .5 .6; .7 .8 .9 ]\n",
    "r.h = [0.4 .2 0.8]'\n",
    "loss = update(r, ([1 0]', [0 1]', [0 1]', [1 0]'), ([0 1]', [1 0]', [0 1]', [1 0]'))\n",
    "println(loss, r.h)\n",
    "\n",
    "update(r, ([1 0]', [0 1]', [0 1]', [1 0]'), ([0 1]', [1 0]', [0 1]', [1 0]'))\n",
    "update(r, ([1 0]', [0 1]', [0 1]', [1 0]'), ([0 1]', [1 0]', [0 1]', [1 0]'))\n",
    "loss = update(r, ([1 0]', [0 1]', [0 1]', [1 0]'), ([0 1]', [1 0]', [0 1]', [1 0]'))\n",
    "\n",
    "println(loss, r.h)\n",
    "\n",
    "println(r.Wxh, r.Whh, r.Why, r.bh, r.by)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##The Data\n",
    "\n",
    "###Shakespeare's Comedies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 2108622\n",
      "\n",
      " --------- Some Text: -------- \n",
      "\n",
      "\tALL'S WELL THAT ENDS WELL\n",
      "\n",
      "\n",
      "\tDRAMATIS PERSONAE\n",
      "\n",
      "\n",
      "KING OF FRANCE\t(KING:)\n",
      "\n",
      "DUKE OF FLORENCE\t(DUKE:)\n",
      "\n",
      "BERTRAM\tCount of Rousillon.\n",
      "\n",
      "LAFEU\tan old lord.\n",
      "\n",
      "P\n",
      "\n",
      " --------- .... -------- \n",
      "\n",
      "y mate, that's never to be found again,\n",
      "\tLament till I am lost.\n",
      "\n",
      "LEONTES\tO, peace, Paulina!\n",
      "\tThou shouldst a husband take by my consent,\n",
      "\tAs I by thine a wife: this is a match,\n",
      "\tAnd made between's by vows. Thou hast found mine;\n",
      "\tBut how, is to be question'd; for I saw her,\n",
      "\tAs I thought, dead, and have in vain said many\n",
      "\tA prayer upon her grave. I'll not seek far--\n",
      "\tFor him, I partly know his mind--to find thee\n",
      "\tAn honourable husband. Come, Camillo,\n",
      "\tAnd take her by the hand, whose worth and honesty\n",
      "\tIs richly noted and here justified\n",
      "\tBy us, a pair of kings. Let's from this place.\n",
      "\tWhat! look upon my brother: both your pardons,\n",
      "\tThat e'er I put between your holy looks\n",
      "\tMy ill suspicion. This is your son-in-law,\n",
      "\tAnd son unto the king, who, heavens directing,\n",
      "\tIs troth-plight to your daughter. Good Paulina,\n",
      "\tLead us from hence, where we may leisurely\n",
      "\tEach one demand an answer to his part\n",
      "\tPerform'd in this wide gap of time since first\n",
      "\tWe were dissever'd: hastily lead away.\n",
      "\n",
      "\t[Exeunt]\n"
     ]
    }
   ],
   "source": [
    "shakespeare_text = \"\"\n",
    "open(\"all_comedies_cat.txt\") do shakespeare_full_text_file\n",
    "    global shakespeare_text\n",
    "    shakespeare_text = readall(shakespeare_full_text_file)\n",
    "end\n",
    "println(\"Length: \", length(shakespeare_text))\n",
    "println(\"\\n --------- Some Text: -------- \\n\")\n",
    "println(shakespeare_text[1:150])\n",
    "println(\"\\n --------- .... -------- \\n\")\n",
    "print(shakespeare_text[end-1000:end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dict{Any,Int64} with 69 entries:\n",
       "  'D'  => 18\n",
       "  '|'  => 69\n",
       "  'Y'  => 39\n",
       "  '\\'' => 6\n",
       "  '.'  => 11\n",
       "  'U'  => 35\n",
       "  'B'  => 16\n",
       "  ':'  => 12\n",
       "  ';'  => 13\n",
       "  'J'  => 24\n",
       "  'Z'  => 40\n",
       "  'o'  => 57\n",
       "  'N'  => 28\n",
       "  'p'  => 58\n",
       "  'F'  => 20\n",
       "  'j'  => 52\n",
       "  '!'  => 4\n",
       "  'y'  => 67\n",
       "  'E'  => 19\n",
       "  'r'  => 60\n",
       "  'm'  => 55\n",
       "  'S'  => 33\n",
       "  'A'  => 15\n",
       "  ','  => 9\n",
       "  'T'  => 34\n",
       "  ⋮     => ⋮"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphabet = sort(unique(shakespeare_text))\n",
    "size_alpha = length(alphabet)\n",
    "println(size_alpha)\n",
    "\n",
    "reverse_alphabet = [ch => i for (i,ch) in enumerate(alphabet)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function make_one_hot(length, index)\n",
    "    v = zeros(Float64, length, 1)\n",
    "    v[index] = 1.0\n",
    "    return v\n",
    "end\n",
    "x = make_one_hot(length(alphabet), reverse_alphabet['.'])\n",
    "assert(1 == x[reverse_alphabet['.']])\n",
    "assert(0 == x[reverse_alphabet['a']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "4\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# Because Julia doesn't seem to have a function to sample from a set of probabilities?\n",
    "\n",
    "function rand_uniform(a, b)\n",
    "    a + rand()*(b - a)\n",
    "end\n",
    "function SampleFrom(probabilities)\n",
    "\n",
    "    # Sum to create CDF:\n",
    "    cdf = Array(Float64, 0)\n",
    "    sum = 0.0\n",
    "    for p in probabilities\n",
    "        push!(cdf, sum + p)\n",
    "        sum = cdf[end];\n",
    "    end\n",
    "        \n",
    "    # Choose from CDF:\n",
    "    cdf_value = rand_uniform(0.0,cdf[end])\n",
    "    index = searchsortedfirst(cdf, cdf_value);\n",
    "\n",
    "    return index;\n",
    "\n",
    "end\n",
    "println(SampleFrom([1 1 1 1]))\n",
    "println(SampleFrom([1 1 10 10]))\n",
    "println(SampleFrom([0.1 0.2 0.7 0.8]))\n",
    "#println(hist([SampleFrom([1 1 10 10]) for i in 0:1000]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"E)u.ADDgYn|i;X\\nxVWzYmn,CpZ;;KE-y( kT|JhMxGlSjd;!\\nV'da&YKJ;OwC]tG\\t|aXhUkVkj:f?f KfMAENmbqZJibSZ(LofFQ\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function hallucinate(r, seed_idx, num_chars)\n",
    "    hallucination = \"\"\n",
    "    prev_ids = [seed_idx]\n",
    "    # clear hidden state (not the weights)\n",
    "    #r.h = zeros(Float64, r.hidden_length, 1) # or maybe not...\n",
    "    # Karpathy doesn't modify h.\n",
    "    for x in range(1,num_chars)\n",
    "        x_vec = make_one_hot(length(alphabet), prev_ids[end])\n",
    "        y_norm,y,r.h = forward_pass(r, r.h, x_vec)\n",
    "\n",
    "        # Now sample from y!\n",
    "        letter_idx = SampleFrom(y_norm')\n",
    "        #letter_idx = indmax(y)\n",
    "        char = alphabet[letter_idx]\n",
    "        \n",
    "        append!(prev_ids,[letter_idx])\n",
    "        hallucination = \"$hallucination$char\"\n",
    "    end\n",
    "    return hallucination\n",
    "end\n",
    "r = RNN(length(alphabet), 500, length(alphabet))\n",
    "hallucinate(r, rand(1:length(alphabet)), 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Chars Trained:0/2108622===========\n",
      "RXZcEFcfZqKbfD)Q-')Mif)UC!ynFNctLjsl.dWDUdIbs!NWjZnQB(aCFI;cqC.Mf,tb?WYVQkDTN|p&\n",
      "(N-MtxNw )Z&)i;(K?A\n"
     ]
    }
   ],
   "source": [
    "training_rnn = RNN(length(alphabet), hidden_size, length(alphabet))\n",
    "chars_trained = 1\n",
    "println(\"======== Chars Trained:\", chars_trained-1, \"/\", length(shakespeare_text), \"===========\")\n",
    "println(hallucinate(training_rnn, 1, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Iteration: 0, Chars Trained:0/2108622 Cost: 105.85266261493149 ===========\n",
      "======== Iteration: 0, Chars Trained:0/2108622 Cost: 105.85266261493149 ===========\n",
      "tDmV[Ft;)BTU k?;i[A;qTgs\n",
      "-\tQYaNzndhQzdQl'.\tAIVx(kgXAEQ\tBJDsCSNUoleBPcZ\n",
      "''.O:.XvX)orovVzXKi]BgmkVuops\n",
      "======== Iteration: 100, Chars Trained:2500/2108622 Cost: 107.16171946695124 ===========\n",
      "aiLt& sh|diuAeibryv]tE-RW T\n",
      "NEVnI )V!  wvL.[a\n",
      "rBTo atooldKNdi(? ,rtmUeBgtts\n",
      "OBWYsS y ,\n",
      "\n",
      "e ihE\n",
      "\n",
      " tn,Y\n",
      "======== Iteration: 200, Chars Trained:5000/2108622 Cost: 105.50344564310039 ===========\n",
      "W s\n",
      "\t  n  \n",
      "TIrhceg)Ue\n",
      "\tm-e  oAa. cbhlrgr eho tto]dn ttde  tEI r\n",
      ":cug,neeesnUcihf r ;oCE\n",
      "rdUUoAnoiLea\n",
      "======== Iteration: 300, Chars Trained:7500/2108622 Cost: 103.51962100847167 ===========\n",
      "isiF tlohnn ioiwecF Myu?  rweTy itltnefdfsdeorer,  d &aeaetMeoregToligde smrt llhyot, and t ugeoaosd\n",
      "======== Iteration: 400, Chars Trained:10000/2108622 Cost: 101.52140245180223 ===========\n",
      "hwsiinhhn ghw hme hl!\n",
      "\n",
      "LuA\n",
      "HLEUNNAopp\n",
      "RWP n t lacAe p uthnton \tcalhnlTgiwi.fe; ..so r gWidhictarstpd\n",
      "======== Iteration: 500, Chars Trained:12500/2108622 Cost: 99.57974736011059 ===========\n",
      " vh \n",
      "gvS, bnaadi, ve\n",
      "\tIoisuN, eu\n",
      "\tK w fr,oihnE irthnyn \tiliaamht, aosceobr y\tit\n",
      "\tEsf n ys, .\n",
      "\tMoI,t\n",
      "\n",
      "======== Iteration: 600, Chars Trained:15000/2108622 Cost: 97.4912455916515 ===========\n",
      " iy bua nte t noliid.\n",
      "\n",
      "NI\taeawiafDurhanwellNagt iw asa iche s y;einS sud\n",
      "\tQAme ce\n",
      " e saveror ehdrn n\n",
      "======== Iteration: 700, Chars Trained:17500/2108622 Cost: 95.48570294210086 ===========\n",
      "adI, me brhoy tham rer am.\n",
      "\n",
      "\tr meleabiutra heveaurubiae gltbtorbmr kdofr atiefrrioonre lial dnd ro; \n",
      "======== Iteration: 800, Chars Trained:20000/2108622 Cost: 93.3015208006519 ===========\n",
      "evatert;\n",
      "\n",
      "CApuce.'emd; G lsd,\n",
      "ks iinorsh '\n",
      "\n",
      "\t(oesd dh  tthers lae'sr,\tsootr; beped aHvs wn tes eaacs\n",
      "======== Iteration: 900, Chars Trained:22500/2108622 Cost: 91.10037472870128 ===========\n",
      "r\td Iedv yeet tch ::sofas cirerut yerrd hes\n",
      "\tNMIg, fatohitesam che 'e yehl tunutg fhe k fhe sa yot. \n",
      "======== Iteration: 1000, Chars Trained:25000/2108622 Cost: 89.01768500944982 ===========\n",
      "- Stnlie:\t'os vet,s,.\n",
      "\tT; moulye,leps Iahe iunathd sone, babgegTos ms mad othy ve y at dot,,\n",
      "NSe tos\n",
      "======== Iteration: 1100, Chars Trained:27500/2108622 Cost: 87.18585071671163 ===========\n",
      "lare gt gn movklilamafishinnahe-vy lire, yogt l hinavad fore pth yigorn\n",
      "\tYok.\n",
      "\n",
      "\tYeik gn.\n",
      "\n",
      "\tTinounegd\n",
      "======== Iteration: 1200, Chars Trained:30000/2108622 Cost: 85.68671356195367 ===========\n",
      "li.\n",
      "\tY,\n",
      "\n",
      "CT\n",
      "A\tAn P foggvard Fand morir vo aIr\n",
      "\tln iutr h!.\n",
      "ION\tOu I drs s me th yyor rind pokeoyg ]e\n",
      "======== Iteration: 1300, Chars Trained:32500/2108622 Cost: 83.89787609664145 ===========\n",
      "ou amak;\tthyyy ftan kt.\n",
      "\n",
      "FS\t(h, sfis\n",
      "\n",
      "\n",
      "ES\tKealed le lloed,S\tLed w Nes, i\n",
      "\n",
      "\twoo?,\n",
      "\tI hifetherabe wy s\n",
      "======== Iteration: 1400, Chars Trained:35000/2108622 Cost: 82.17193992115669 ===========\n",
      "s cit hy wofasd tueseys Dl covinr.\n",
      "\n",
      "\tENN\twy lhe mimceygishosmre tracaytlasoltreroy fiv, the act, pat\n",
      "======== Iteration: 1500, Chars Trained:37500/2108622 Cost: 80.76834947783846 ===========\n",
      " itpere a.t at tke aklf thoe maos mupare ye torh dd:\tE'thits\n",
      "\tbylepd ce whan ky tomas elnt tod dhand\n",
      "======== Iteration: 1600, Chars Trained:40000/2108622 Cost: 79.4518929970728 ===========\n",
      "s\n",
      "\n",
      "CuSENOOENOEHLEPEDxFntou outawoun\n",
      "\n",
      "CS\tSot Looleue\n",
      "\n",
      "\n",
      "\n",
      "KAPSNAEPHS[S\tNat,'\tseliis motowe mirs mitr mv\n",
      "======== Iteration: 1700, Chars Trained:42500/2108622 Cost: 78.2066983735306 ===========\n",
      " thy thakn!\n",
      "\tI thild astst,\n",
      "\tS sheanete nine npinespe mo hins pir; thenbita; wourtdoedit okther thar\n",
      "======== Iteration: 1800, Chars Trained:45000/2108622 Cost: 76.78674568047582 ===========\n",
      "\n",
      "\tThe I In;\n",
      "\n",
      "\tS reeamy uche bath y weor, ian heene le thare\n",
      "\tFha bntnkire the\n",
      "\tEoug courdachess when\n",
      "======== Iteration: 1900, Chars Trained:47500/2108622 Cost: 75.53720303250608 ===========\n",
      "  o'd,\n",
      "\tI lor bueir,\n",
      "\tthe pathind aurnd.\n",
      "\n",
      "LSU\tOebd, tore Fghele hy wmkgeistomeng lanv.\n",
      "\n",
      "\tIS\tMn Sot t\n",
      "======== Iteration: 2000, Chars Trained:50000/2108622 Cost: 74.29823598092618 ===========\n",
      "roue sedrte maraegeby thand lof ghciou ams n the sr secd gfamt thin pneabieese douigoh te;\n",
      "\n",
      "\tI the s\n",
      "======== Iteration: 2100, Chars Trained:52500/2108622 Cost: 73.12684591489814 ===========\n",
      "indd hiout hihk vtherd.\n",
      "\n",
      "US\twenean onetheris :ne to ls-ert wort'ne; ur,\n",
      "\tWon.\n",
      "\n",
      "\n",
      "PAROAFE'M'tod\n",
      "\tMupe \n",
      "======== Iteration: 2200, Chars Trained:55000/2108622 Cost: 72.00997588569484 ===========\n",
      "mt anN.\n",
      "\n",
      "\n",
      "F)re ayy hee Hout meess ulthink-\n",
      "\tAn\t; torar har yo shr ilve do stry hie toher: cise  hard\n",
      "======== Iteration: 2300, Chars Trained:57500/2108622 Cost: 71.00843746231915 ===========\n",
      "y, thas heis wi snal I mrel g.\n",
      "\n",
      "LALEruroull may don mryow'toy ard the. thr; doimertger I teBord in s\n",
      "======== Iteration: 2400, Chars Trained:60000/2108622 Cost: 69.93871070751501 ===========\n",
      "on er.\n",
      "\n",
      "LELELEU\n",
      "\tFoug soe mlot thoJnp teowewn\n",
      "\tHat'amg thous eaerey le, tirs sheell.\n",
      "\n",
      "\tEour. likin m\n",
      "======== Iteration: 2500, Chars Trained:62500/2108622 Cost: 69.3784156366707 ===========\n",
      " theFS blald\n",
      "\t[insaigd it in as aldoldu vnr.\n",
      "\n",
      "PAROUNEA\n",
      "\thaicgesthand oave date nesich hit abe,d thar\n",
      "======== Iteration: 2600, Chars Trained:65000/2108622 Cost: 68.6833828682951 ===========\n",
      " snald chal dis?\n",
      "\n",
      "\n",
      "PE bandeende fle anlly where hal\tIfin avt fhave bett &ele sacurec herag ther irtw\n",
      "======== Iteration: 2700, Chars Trained:67500/2108622 Cost: 67.9934790958395 ===========\n",
      "cove wous yourthet-\n",
      "\tBoit\n",
      "\n",
      "CES\tMfouve that \tal forinkaum; woe and farg berare phin ty\n",
      "\tWr astn Fy ho\n",
      "======== Iteration: 2800, Chars Trained:70000/2108622 Cost: 67.55803266191806 ===========\n",
      "tkire, mowt ald,\n",
      "\t[Sitesh I laI m'lisprels Fperotte toog hevat cordatome ifou, Fe ws hitre on: thang\n",
      "======== Iteration: 2900, Chars Trained:72500/2108622 Cost: 67.15763158196425 ===========\n",
      "ge\n",
      "\tcen sost woure whre s oaat theer fthest thou whit dosicl,\n",
      "\tFEteeng theerm; lfat cove to\ththllid\n",
      "\n",
      "======== Iteration: 3000, Chars Trained:75000/2108622 Cost: 66.61688456716918 ===========\n",
      "thanct dyee sing sherre yow thof ebe\n",
      "COhe,\n",
      "\tFmiver hitlr , nol; jil gousamg. syour hals riif ilg ak,\n",
      "======== Iteration: 3100, Chars Trained:77500/2108622 Cost: 66.2925068935565 ===========\n",
      "Ar;\n",
      "\tlobd: haim, aike ar think istrimed hito Gu haut of bo hame\n",
      "\tIagh?\n",
      "\tTbich f ad,\n",
      "\twin\n",
      "\t[om tarthy\n",
      "======== Iteration: 3200, Chars Trained:80000/2108622 Cost: 65.78294705287357 ===========\n",
      "oragve af an. psimlrtpem abos, feccsithe radet,: nthyed. Tess momy. thir, lod\n",
      "\tnoald las sgats of at\n",
      "======== Iteration: 3300, Chars Trained:82500/2108622 Cost: 65.1407463381609 ===========\n",
      "  tou kece wave Whe\tepscorows unoule,\n",
      "\tWheem wiard oofe woutwhid kimS\tEor I wonat,ag heok sot white,\n",
      "======== Iteration: 3400, Chars Trained:85000/2108622 Cost: 64.89189674067768 ===========\n",
      " bfobt]l\n",
      "\tfumy hilitiarss sonrarnciy and\t'orsescomtuas thanggentactiveud wherillta\n",
      "\tdo t of fo I 'co\n",
      "======== Iteration: 3500, Chars Trained:87500/2108622 Cost: 64.5377461012087 ===========\n",
      "Five and\tAronl sf ald fir thavuserul fowist , ofM artnlad.\n",
      "BFES\tAnom.\n",
      "\n",
      "\tit doy 'coresl, torapewor of\n",
      "======== Iteration: 3600, Chars Trained:90000/2108622 Cost: 64.10036644659112 ===========\n",
      "emkps wy pofot dot\n",
      "\tTo fe: I alt ant.\n",
      "\n",
      "\n",
      "TETLEMHEELS\tI areg lerd.\n",
      "\tLh the mere, pothreres doarspf or.\n",
      "======== Iteration: 3700, Chars Trained:92500/2108622 Cost: 63.633514848243976 ===========\n",
      "agenome so wion toss\n",
      "\tWoord,\n",
      "\tWiy I , haagon wowiicte.\n",
      "\n",
      "SA\tEond.\n",
      "Wwank wolkst owo gorese okd\t ie hy \n",
      "======== Iteration: 3800, Chars Trained:95000/2108622 Cost: 63.21603009205093 ===========\n",
      "n ig;held ithiakesl?\n",
      "\tWheit ind yot hat il;\n",
      "\tAnthis ifusagfo thas lirtndhertulires and er\n",
      "\n",
      "Mor .\n",
      "\n",
      "BE\n",
      "======== Iteration: 3900, Chars Trained:97500/2108622 Cost: 62.806032776260004 ===========\n",
      "em thathelle cenlg me of tist codd ce\n",
      "\tshethdfiniw, whenrse, Lansteld asn a mondibl\tNatr. ith jlot m\n",
      "======== Iteration: 4000, Chars Trained:100000/2108622 Cost: 62.65497073420353 ===========\n",
      "sarput, anharak his. I I eras twans Gard'e teacuend an wi.\n",
      "\n",
      "Fand; Lo?\n",
      "\n",
      ";.\n",
      "\n",
      "Fhif dhiteddist neK dens \n",
      "======== Iteration: 4100, Chars Trained:102500/2108622 Cost: 62.25112232563085 ===========\n",
      "ci s youpiripaapf Sely to cererdy th an]\n",
      "\n",
      "\tANourd, anct ou lya thin\tAf ont\n",
      "\tWhoC se ouq, tor: eirn: \n",
      "======== Iteration: 4200, Chars Trained:105000/2108622 Cost: 61.80495732974663 ===========\n",
      "that]\n",
      "\n",
      "BERTROOLEELENA\tI atse,, Cais.\n",
      "\n",
      "For shis dethest Forst Lhe rou sthet t.\n",
      "\n",
      "Sicu orit cet dou has\n",
      "======== Iteration: 4300, Chars Trained:107500/2108622 Cost: 61.455465705778344 ===========\n",
      "ss and\tar I at but tatof so lilsI ot cerellas Lomd ink!\n",
      "\tWhin.-LLLS\tBo RTRA\tSof blee of\n",
      "\tThe: bouy a\n",
      "======== Iteration: 4400, Chars Trained:110000/2108622 Cost: 61.5605844307487 ===========\n",
      "en gorend fe pemeren sheaves fhe wowhy snacth; yor tour thowgots]\n",
      "\n",
      "\tAfdoint'llmes wthiillr lito, tha\n",
      "======== Iteration: 4500, Chars Trained:112500/2108622 Cost: 61.32563957904495 ===========\n",
      "awto here, of es ans]\n",
      "\n",
      "\tit coupe the ane, an'd of his meett hey owt;\n",
      "\tbet.\n",
      "\n",
      "ROLLES\tAn ane.\n",
      "\n",
      "\t[his he\n",
      "======== Iteration: 4600, Chars Trained:115000/2108622 Cost: 61.18639632997457 ===========\n",
      "rell wis unt cardeith pont lethe courttiing\n",
      "\t[hill he chant nos d lond when\t'nate sur; un ce fice mo\n",
      "======== Iteration: 4700, Chars Trained:117500/2108622 Cost: 60.95236509095477 ===========\n",
      "youln whent nreWellatne, bot Gimm you.\n",
      "\n",
      "PAxELES\tbearcer mefom, Whin shetesa sfine', a tisn;\n",
      "\tArs,\n",
      "\tT\n",
      "======== Iteration: 4800, Chars Trained:120000/2108622 Cost: 60.6289594660929 ===========\n",
      "forer ers dugusd gEne on yord\n",
      "\ttheouangegthesf I off vord I-Whad ast is eave to\n",
      "\tTis'tenwer.\n",
      "\n",
      "COU\tTo\n",
      "======== Iteration: 4900, Chars Trained:122500/2108622 Cost: 60.57035879639386 ===========\n",
      " now wrere\n",
      "\tTher ce.\n",
      "\tbus end ar Fthe lou co baVe oundn mlour ake be:\n",
      "\tWhour pfore\n",
      "\tMive seno pao ou\n",
      "======== Iteration: 5000, Chars Trained:125000/2108622 Cost: 60.306050169154105 ===========\n",
      "incelom, tho thane theud meell sun youre to foa hooten therve wou -sigtat iist punour natou trou oth\n",
      "======== Iteration: 5100, Chars Trained:127500/2108622 Cost: 60.19007194506249 ===========\n",
      "se, and urstit I ver tr pyyer, Mely wiik fore thy doucoaren\n",
      "\tSet'd\n",
      "\tWhe nouence\n",
      "\tThou you cowe its r\n",
      "======== Iteration: 5200, Chars Trained:130000/2108622 Cost: 59.79855443047962 ===========\n",
      "\n",
      "\tAx tid ut may bif ols mhow shalo my shis  had pathing sar Whimur fe sit wou your ar sof bend an.\n",
      "\n",
      "\n",
      "======== Iteration: 5300, Chars Trained:132500/2108622 Cost: 59.16283881062954 ===========\n",
      "\n",
      "\n",
      "\tI ghis kif rang oeld dou pewre hithle so ar iw wove key hers; a mame fo it mn mere.\n",
      "\n",
      "KIANA\tSo rig\n",
      "======== Iteration: 5400, Chars Trained:135000/2108622 Cost: 58.93798473183446 ===========\n",
      "y\n",
      "\twhem ciog theepce,: nove ond lfeat feret, jey so eyos llimecerer thar besit noured,\n",
      "\tSner?\n",
      "\n",
      "BERTR\n",
      "======== Iteration: 5500, Chars Trained:137500/2108622 Cost: 59.82883040041277 ===========\n",
      " no thet ofk ther fattex ond sis a'd theraw hise co ro har\n",
      "\tI giprouding: fave I it dece feoul, mat\n",
      "\n",
      "======== Iteration: 5600, Chars Trained:140000/2108622 Cost: 59.62814715455076 ===========\n",
      "rither,\n",
      "\tYour al.\n",
      "\tdor my br must hr brey an Dor brof cor g\twesy youl?\n",
      "\n",
      "\tFowe be.\n",
      "\tA gelaklot\n",
      "\tBis I\n",
      "======== Iteration: 5700, Chars Trained:142500/2108622 Cost: 59.524177368114124 ===========\n",
      " hespe fim yo\n",
      "\tpad womath ag lrourer orieghis of seoghere hens, ar bey loldouth ar no as thiore woll\n",
      "======== Iteration: 5800, Chars Trained:145000/2108622 Cost: 59.419157777181056 ===========\n",
      "our yoll! cer thaks  this\n",
      "\twamy]\n",
      "\n",
      "\tburtive gow mipfocke\n",
      "\tsihe dill, ikd to dobllendp you ce tule bli\n",
      "======== Iteration: 5900, Chars Trained:147500/2108622 Cost: 59.295476020222196 ===========\n",
      "e wat he thiU\tSurimore, cam in srom Ef\n",
      "\tWhou ore liis deat sharet\n",
      "s ave bue, bry cofer sicees, endan\n",
      "======== Iteration: 6000, Chars Trained:150000/2108622 Cost: 59.131592340609714 ===========\n",
      "ve seed, ondburend int hath nagled he the s?\n",
      "\n",
      "Cd\tShey he ble ming g p: dorpt of&kHl You gore you the\n",
      "======== Iteration: 6100, Chars Trained:152500/2108622 Cost: 59.0895289195102 ===========\n",
      "catheres art you that fouremy durp my t wou me pet fomy leis.\n",
      "\n",
      "Fnd, mer; intle\n",
      "\tof pay ild fak to me\n",
      "======== Iteration: 6200, Chars Trained:155000/2108622 Cost: 58.82917632249528 ===========\n",
      "\tdou; inclr ye hangect.\n",
      "\n",
      "\n",
      "COUNDE\t[Exoun lrangure, mam y to thout wert thlo thy wim geve hendpure,\n",
      "\tF\n",
      "======== Iteration: 6300, Chars Trained:157500/2108622 Cost: 58.725468979758496 ===========\n",
      " hrakt]\n",
      "\n",
      "\tCENDA himsus wo certene fuy me por detelce't and whit ouck o kofoelg'is and;\n",
      "\tGrate tway t\n",
      "======== Iteration: 6400, Chars Trained:160000/2108622 Cost: 58.48008137087489 ===========\n",
      "ns; houghay\n",
      "\tis\n",
      "\tWu lece desting; to dory dide shar\n",
      "\tbcishinld you troat fur fut ar disen d ar, 'olf\n",
      "======== Iteration: 6500, Chars Trained:162500/2108622 Cost: 58.21956834790454 ===========\n",
      " thet hispanse, mur, contlendit you d dueth\n",
      "\n",
      "ROS]\n",
      "\n",
      "CELIAD\tHolcentont: diter foour thme shanse pald n\n",
      "======== Iteration: 6600, Chars Trained:165000/2108622 Cost: 58.21601957635138 ===========\n",
      "edyes, thou pos .\n",
      "\n",
      "\tTha dove',\n",
      "\tWhy d, lled.\n",
      "\tB hith bestle\n",
      "\tNih ind's BELI yed borid morke thereblo\n",
      "======== Iteration: 6700, Chars Trained:167500/2108622 Cost: 58.35135921868189 ===========\n",
      "ll: in shagl fyjeninn igopred,.\n",
      "\n",
      "AUACEAKE mire werp futhle doo wintere.\n",
      "\n",
      "CBENG\tand bain thot and wit\n",
      "======== Iteration: 6800, Chars Trained:170000/2108622 Cost: 58.13754218913037 ===========\n",
      "er: wtre tham shat fuur dot bediten, this or dow my thes hang, he woudes meve to ae thlron theres.\n",
      "\t\n",
      "======== Iteration: 6900, Chars Trained:172500/2108622 Cost: 58.04867608998928 ===========\n",
      "l stond Whear'.\n",
      "\n",
      "DOSAMI\tI\tAI onN cores.\n",
      "\n",
      "DRLCERIAPIND OOCs; I fir tor len tave lecouy and by wat wor\n",
      "======== Iteration: 7000, Chars Trained:175000/2108622 Cost: 57.92636367237383 ===========\n",
      "esuat win arm nelike I hert, the us oy los you dndere'st yoln yom the deise\n",
      "\tFuts bus will.ROSCOOROU\n",
      "======== Iteration: 7100, Chars Trained:177500/2108622 Cost: 57.85429168315289 ===========\n",
      " cathe heank'tur thet.\n",
      "\n",
      "LUNAE\tI\n",
      "\tther diorg noud and Jass seiks hive, cover teubeagraie. I\n",
      "\tA for th\n",
      "======== Iteration: 7200, Chars Trained:180000/2108622 Cost: 57.82287589891141 ===========\n",
      "I foby han ige to pvint gith erouenw;.\n",
      "\n",
      "\n",
      "UCOUES\tYO\tto, is, horedhen lyou pust havis,\n",
      "\tRingin sees\n",
      "\tA\n",
      "======== Iteration: 7300, Chars Trained:182500/2108622 Cost: 57.792782080750726 ===========\n",
      "RANES\tYaou fat no hem bofe forpe asheme sharst doo mofy hisl in?\n",
      "\n",
      "UBENNI\tVevees ire in sonktrr ticll\n",
      "======== Iteration: 7400, Chars Trained:185000/2108622 Cost: 57.606258435829666 ===========\n",
      "heallrag\n",
      "Clyas apisp thinl nathe; sno fis hath The verriel wavy wive vis\n",
      "\tWar ahat I inl tiblesthe n\n",
      "======== Iteration: 7500, Chars Trained:187500/2108622 Cost: 57.533849392563695 ===========\n",
      " diak, & nom in! no hour bunntI herwar faren twat tm is,\n",
      "\tAndilfimy is!\n",
      "\tI'des at weating sucait tol\n",
      "======== Iteration: 7600, Chars Trained:190000/2108622 Cost: 57.44629900066572 ===========\n",
      "nave frace sas erlen.\n",
      "\tMund sthey tree! you a treekp.\n",
      "\n",
      "Ch\n",
      "\n",
      "\tAnd agr thid baing thof I pid,\n",
      " bye the \n",
      "======== Iteration: 7700, Chars Trained:192500/2108622 Cost: 57.29534727798488 ===========\n",
      "fentenoth ar shues il thesh ive all hancce thact orlle, her gothip rames\n",
      "\tMing and whand's oit ninkl\n",
      "======== Iteration: 7800, Chars Trained:195000/2108622 Cost: 57.31028609912154 ===========\n",
      "\t[E'me thed zothind. I riit beur, shear:thee ad?\n",
      "\n",
      "SOUNIAS\tIs a padess Whours\n",
      "\tFig\n",
      "\tWeveeg.\n",
      "\n",
      "OCSCEN\tO\n",
      "======== Iteration: 7900, Chars Trained:197500/2108622 Cost: 57.232036904447085 ===========\n",
      "ele se peofdoved nityouldheroe, sust fo at usterimy\n",
      "\tNn-lere atle tospatt.\n",
      "\tPhomed, your iask?\n",
      "\n",
      "\t[EU\n",
      "======== Iteration: 8000, Chars Trained:200000/2108622 Cost: 56.94445012711839 ===========\n",
      "pnrd ofich hat where phouplar,\n",
      "\tsire:\n",
      "\tJumoud thave fet cegeder?\n",
      "\tHend, and wild is the RTot makes u\n",
      "======== Iteration: 8100, Chars Trained:202500/2108622 Cost: 56.6022789790028 ===========\n",
      "gs.\n",
      "\n",
      "AOLSALIND\tImar zell ghakle ald gher\n",
      "\tFat wa qure you deakas of tos\n",
      "\tfereme seike whee lit wlrei\n",
      "======== Iteration: 8200, Chars Trained:205000/2108622 Cost: 56.285138406987905 ===========\n",
      "ke med sid wing in ereth willy\n",
      "\tHerenvard trenst remere\n",
      "\tyou chery yound gould trinces nof tho moer \n",
      "======== Iteration: 8300, Chars Trained:207500/2108622 Cost: 55.90988644179525 ===========\n",
      "le tofle, fole parlevn an yove tho ghath; loud weverd shat on sich wiid ttheed mence soue nom deseng\n",
      "======== Iteration: 8400, Chars Trained:210000/2108622 Cost: 56.05956356326904 ===========\n",
      "le I no N aa youlim\n",
      "\twam pattand she hoo my an the?\n",
      "\n",
      "\n",
      "\n",
      "CEAMIO\t[\tendly.\n",
      "\n",
      "ROSCES\tOhas that.\n",
      "\t[All mepe\n",
      "======== Iteration: 8500, Chars Trained:212500/2108622 Cost: 56.240442712698645 ===========\n",
      "Oe meren jime t.\n",
      "\n",
      "\t[Yas you\n",
      "\tbucel? I lamyge, on vorver: natind a to mever, ake fotrer\n",
      "\ttritlandbug!\n",
      "======== Iteration: 8600, Chars Trained:215000/2108622 Cost: 55.93965929858043 ===========\n",
      "seer\n",
      "\tCele an\tkraglen of sor, ustheowaret\n",
      "his youwe ofss hodver sino, I plet mady wiis then; the an,\n",
      "======== Iteration: 8700, Chars Trained:217500/2108622 Cost: 56.00601397456388 ===========\n",
      " minel,\n",
      "\twere ther the stath.\n",
      "\tAnd that notk broed\n",
      "\tTheak sile hy toaby of in il nasterter gast\n",
      "\tAnd\n",
      "======== Iteration: 8800, Chars Trained:220000/2108622 Cost: 55.891222090206554 ===========\n",
      "\tFryours ORCHA WRyour bey mo Phee lA a wink shore fiplrare the leviy stow min eth she glioo no I whe\n",
      "======== Iteration: 8900, Chars Trained:222500/2108622 Cost: 55.741507022303175 ===========\n",
      "hes\n",
      "\tso axt; whoutun'boves, him rice:\n",
      "\tOn pery, thed why\n",
      "\tTray?\n",
      "\tmerthacl, nais,'dell ther an word\tI\n",
      "======== Iteration: 9000, Chars Trained:225000/2108622 Cost: 55.4706224623044 ===========\n",
      " hat ie wisteand, ofoch maer tht of a whath the\n",
      "\tRollath andomest quit]\n",
      "\n",
      "OROSALDVIND\tSostperseroumy \n",
      "======== Iteration: 9100, Chars Trained:227500/2108622 Cost: 54.95748045513756 ===========\n",
      " aet\n",
      "\tAf hern dill dorpe kmorerary in, I co thoor no ald dothe:\n",
      "\n",
      "\tNor erellleUy and youesss.\n",
      "\n",
      "ROSALD\n",
      "======== Iteration: 9200, Chars Trained:230000/2108622 Cost: 54.69709203766039 ===========\n",
      "d lou\n",
      "\tfove hin 'thall and to cof\n",
      "\tYee\n",
      "\tthese; soy a me! him\n",
      "\tpownot me-peesess hit you\n",
      "\tse bet hme \n",
      "======== Iteration: 9300, Chars Trained:232500/2108622 Cost: 54.79357308550431 ===========\n",
      " no anT formesll? Fa Wo whlom wh; lust he soo, I' wethin ourtno, uthotivest of wolete wist\n",
      "\tCof shef\n",
      "======== Iteration: 9400, Chars Trained:235000/2108622 Cost: 54.76486817935055 ===========\n",
      "n shavt he her thae of se,\n",
      "\tGilfons ere ton a dorglonen hile eo cublath I him sur ond sers. I the ha\n",
      "======== Iteration: 9500, Chars Trained:237500/2108622 Cost: 54.83714266674204 ===========\n",
      "r sup natler bowigling briir.\n",
      "\tIn han nos ghis, prot\n",
      "\tCez yah! LI Guke wer,, by athe with s o her:\n",
      "\t\n",
      "======== Iteration: 9600, Chars Trained:240000/2108622 Cost: 54.79572831981653 ===========\n",
      "t mr.es het, you and ce sure poreil dous's and! sorthin and youraby thours t treagld osather cad wow\n",
      "======== Iteration: 9700, Chars Trained:242500/2108622 Cost: 54.92033138050964 ===========\n",
      "ee-ange stey, brot hou co:\n",
      "\tTar yot gomporo noke werce coven;\n",
      "\tAru.\n",
      "\n",
      "LIKG\n",
      "\tWid ther ist.\n",
      "\n",
      "LALIA YO\tA\n",
      "======== Iteration: 9800, Chars Trained:245000/2108622 Cost: 54.865796566595755 ===========\n",
      " buth all be ant to morn oomen soue spo do sa, not felle wied wouls and bupoury ond ove with ]\n",
      "\n",
      "\t[fo\n",
      "======== Iteration: 9900, Chars Trained:247500/2108622 Cost: 54.593649246464715 ===========\n",
      ":\n",
      "\tGodll geke ham's I eime you? Hexe phine thege, then thuck as I fle and lo hear I or burdees, id, \n",
      "======== Iteration: 10000, Chars Trained:250000/2108622 Cost: 54.631687501217904 ===========\n",
      "e\n",
      "\tAnd beent a hy hin, I shim I wo cure fad. AND\tIfat I to wher m andade and twe: deemy dety tare th\n",
      "======== Iteration: 10100, Chars Trained:252500/2108622 Cost: 54.47327686898935 ===========\n",
      "eag sleit ity to lath Ropered a, I sheas you sain,,\n",
      "\tnow bved made to that theagp,\n",
      "\tdo hrpill sureby\n",
      "======== Iteration: 10200, Chars Trained:255000/2108622 Cost: 54.67238050078578 ===========\n",
      "eve to s-mant; wreend the and de; twreras, whis blot lour winktrrestre. ROSALIThars had, and suller \n",
      "======== Iteration: 10300, Chars Trained:257500/2108622 Cost: 54.81281702740381 ===========\n",
      "\tHonr,\n",
      "\tTo too bdswer notin:;\n",
      "\tWelfS\n",
      "\t'gomy whos thor be salne-pod fon put woveath aoy I fyeinge han\n",
      "======== Iteration: 10400, Chars Trained:260000/2108622 Cost: 54.757202142165575 ===========\n",
      "d cave Onandath, mphisgedyes mas.\n",
      "\n",
      "Sllle d k, evan mbe-tere puerecpo tor a hegk wounty pyoun thou no\n",
      "======== Iteration: 10500, Chars Trained:262500/2108622 Cost: 55.768490496501684 ===========\n",
      "ou And Sor nott.\n",
      "\n",
      "Whesirsss faylin a dese is tpaif ang; ify,\n",
      "\tWim', fid withhent wdoddef leal, a to \n",
      "======== Iteration: 10600, Chars Trained:265000/2108622 Cost: 56.032965752489226 ===========\n",
      " suldies fyoncamigh bunt achuncect Jhive lids!\n",
      "\tthe chathee\n",
      "\twich, erale bow,\n",
      "\t'nit. .\n",
      "\n",
      "\n",
      "DINHA\tDine \n",
      "======== Iteration: 10700, Chars Trained:267500/2108622 Cost: 56.03816149661035 ===========\n",
      ":\n",
      "\tAr her ssilun in I, Salbeds, theve ande n ive to dorrne'w go ast ind bieth\n",
      "\tFaprind wistre bealld\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "interrupt\nwhile loading In[19], in expression starting on line 5",
     "output_type": "error",
     "traceback": [
      "interrupt\nwhile loading In[19], in expression starting on line 5",
      "",
      " in + at array.jl:725",
      " in forward_pass_backpropogate at In[7]:78",
      " in update at In[12]:3",
      " in anonymous at no file:19"
     ]
    }
   ],
   "source": [
    "#for seq_length in [20,100,200,400]#,20,20,20]\n",
    "i = 0\n",
    "smooth_loss = -log(1.0/length(alphabet))*seq_length # loss at iteration 0\n",
    "println(\"======== Iteration: $i, Chars Trained:\", chars_trained-1, \"/\", length(shakespeare_text), \" Cost: $smooth_loss ===========\")\n",
    "while true\n",
    "    if chars_trained+seq_length+1 >= length(shakespeare_text)\n",
    "        println(\"========= DONE!! ===========\")\n",
    "        break\n",
    "    end\n",
    "    x_vecs = [make_one_hot(length(alphabet), reverse_alphabet[x]) for x in shakespeare_text[chars_trained:chars_trained+seq_length]] \n",
    "    truth_vecs = [make_one_hot(length(alphabet), reverse_alphabet[y_]) for y_ in shakespeare_text[chars_trained+1:chars_trained+seq_length+1]]\n",
    "\n",
    "    if i % 100 == 0\n",
    "        println(\"======== Iteration: $i, Chars Trained:\", chars_trained-1, \"/\", length(shakespeare_text), \" Cost: $smooth_loss ===========\")\n",
    "        seed_idx = reverse_alphabet[shakespeare_text[chars_trained]]\n",
    "        println(hallucinate(training_rnn, seed_idx, 100))\n",
    "    end\n",
    "\n",
    "    (loss,) = update(training_rnn, x_vecs, truth_vecs)\n",
    "    smooth_loss = smooth_loss * 0.999 + loss * 0.001\n",
    "\n",
    "    chars_trained += seq_length\n",
    "    i += 1\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fhat and ander broos by I hend dot sass the dith; the kam,\n",
      "\tThishe\n",
      "\tAnd;\n",
      "\tMar eave oorsf ther na. Hils ir?\n",
      "\n",
      "DRSAKEUS IUh E\n",
      "\n",
      "OUNUEHEwOSALINDEN\tThat sires my, to prootstharen Afeers save wind the sep,\n",
      "\tDot liads Sald,\n",
      "\tWork weat bo wistires Anour pristed, will trens with acpering!\n",
      "\tH t, mithid.\n",
      "\n",
      "SALIN]\n",
      "\t'thed she pnrt, fathe orto dahis, eave ond go bedold mearsaid you, afure lotrs hourd moury nike the muse,\n",
      "\tHe hamed,\n",
      "\tAr, to har the'd\n",
      "\tTh my sarss tor!\n",
      "\n",
      "\tTo prowied: qucheny soxes boniast, till,\n",
      "\tWoml waw fiallf.\n",
      "\n",
      "\t[Ericedou.\n",
      "\thyam merfe, we we sold\n",
      "\tBir willt canou bet boL my reblnt Somein, Dy Sippe, amit\n",
      "\tThimg,\n",
      "\tThourr verincu, ast raperasurfes.\n",
      "\tI mave, theaw:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "TOSCKE SHSARBIN E ly I shouris the pees pracithel bind'nge this so no cof bacvesile To thoung St I spoun hcom'd\n",
      "\tHer,\n",
      "\tYouand hith\n",
      "\tOf, ay disctilsd; os'se murs.\n",
      "\n",
      "SALIA\tIou moay broud weatheco's\n",
      "\tFfostantinnd ard ves wourren, ammus,;\n",
      "\tEnd cheng? tobe fi the\n",
      "\tThis ard as af instorn\n",
      "\tThate dime, Modeds be; numbrove fou's warves hile your'gheurd,\n",
      "\tild.\n",
      "\tWwitheant wave tre ode mo here rshy in frive hithe bencenses to plon\n",
      "\tHtorerour lantench\n",
      "\tAno, Todpis madse,\n",
      "\tMofahes terotpelanous to plath soteme,\n",
      "\tIy Sver-.\n",
      "\n",
      "\tProu meaddsien, brraty anU until' saly thond srerl gumy or peco,\n",
      "\tchome! Ithe eor: Mofkeded to seas,\n",
      "\tNoo heont!\n",
      "\tBay in pot nim dovum.\n",
      "\n",
      "\tHe doll mangee theved, fate, mester'd.\n",
      "\n",
      "FRyLIUM\tSess\n",
      "\tWor. Loutsofdeacthen oud, fhear thay fordiouf,\n",
      "\tO mies: and this dover\n",
      "\tThy thee,\n",
      "\tMat lanleancedeft ouplais thinss minctir,\n",
      "\tHeverst thin natall\tNy,\n",
      "\tWisim angiight\n",
      "\tforve wis arusems fore; myre, porithy fomced yo om and my, frropce;\n",
      "\tYoureso Oire oured'\tI; to cores thof thebr,\n",
      "\tAnds heer whecurs tais and dos miplingth,\n",
      "\tMoof rat yourT Mikartheebrond.\n",
      "\n",
      "\tH(STU\tHreep;\n",
      "\tMimuse-werd, offe fook wird,\n",
      "\tMidthin fo gor thy old forl,\n",
      "\tAnd may sured thall,\n",
      "\tWO ichin', ooln fuld um aprik moone nvetenher.\n",
      "\tPhoun outher.\n",
      "\tAuse spret: PI flalenmard tyek for heristered,\n",
      "\tAnd the my, of is my that fagast allisglontt\n",
      "\tIney tour.\n",
      "\n",
      "\n",
      "\t[Eh un lase of the covey moo sracl mre and: dohe my thasw, with ofstes arss that sintnst wist the tho the herat]\n",
      "\n",
      "\n",
      "\n",
      "EUCS\n",
      "\tATO\n",
      "\tYod to lfo weced,\n",
      "\tWhene tho So\n",
      "\tOnesp ustornarvertud of butheC seor kile and ma thect to fouk.;\n",
      "\tIwand!\n",
      "\n",
      "Mauss lathie the lovestor winieg'd my oremingow. I foves eirefs]\n",
      "\n",
      "OnNONIO dsow ce,\n",
      "\tAst tf ther theed croolf ad thine ole lave seedofeby,\n",
      "\tThour thous ford, DO VES\tWill, thear ond t sod inath thel west or je?\n",
      "\tSave magt to thou e trot trengsth'n mefef:\tA soriser inO wh, O wilith brime\n",
      "\tAnd boune didened hyo cumene, thys any mavef, Af wie fordapmonty. ISlrahT Wacts of PThatse?\n",
      "\n",
      "\tno me.\n",
      "\n",
      "TONI, I\n",
      "\t|\n",
      "\tButt cee hed deatherago anten,\n",
      "\tyis Suas, dey\n",
      "\tWey, tha llot I treilte,\n",
      "\tAf is waves,\n",
      "\tA serme shak DUZLerteze fpastgeg perutheapy fI wavust sesh\n",
      "\t: hat raqupy sooreme:-An bourve Youm sust thangots I sidf, whall as theret regtheakisne, weeven thou ceacech's morend ang and afd\n",
      "\tOy here, buwl;\n",
      "\tTave; thetent; twill is deer of notL\tYoud,\n",
      "\tAinl:\n",
      "\tAnd verliche,\n",
      "\tConvele ford waviwaf chaly stheed'd.\n",
      "\n",
      "\t[Sxale soflet]\n",
      "\tAle our onidrtagherg tharrcstured ald preee on JELIA\tA homher belighat wavy alghus, wpor\tif,\n",
      "\tGnafpr, to thin the whe anisn the seree boure,\n",
      "\tVumy end misede coactichaat senom! youthenour woully the treth thit]\n",
      "\n",
      "HESOS\tBy hale deaisy, nuck.\n",
      "\tShis liegh of marern?\n",
      "\n",
      "TALIN\tSo misensd seeres Savingort,\n",
      "\tTR t here\n",
      "\tThe sterd, is by surend nee a fach and my aleds sether.\n",
      "\n",
      "IANUS\tHe pemy thes lonctings maceres the, bowe go junt thes dody treRtour thillld on them! Alllust tas me bravn matt esee misthezrant Lishes lurdingeng ther thit have\n",
      "\tAnd beve,\n",
      "\tA the merwseefstartge wim himmers then thed thou houre foshernd oun\n",
      "\tAy tos\n",
      "\tOny hin the wiaalen, of beich 'llstinourd,\n",
      "\tEr:\n",
      "\tAn lam yve that on ad,\n",
      "\tTO HReits if traen me her, Oflrall- iaittses,\n",
      "\tAnd wiunt willosse\n",
      "\tgawe, hey erring;\n",
      "\tThiest.\n",
      "\n",
      "MUKE SE totatill Rered,\n",
      "\tWivlin he uE on otp bamts lingtomy,\n",
      "\tBuvund the ca wal omastet thimake wa gr tove wimly me sit thKs modicu lnnock; the the\n",
      "\tTall,\n",
      "\tSpand dimh at,?\n",
      "\n",
      "\n",
      "DESALIND\t[Efurt I seon.\n",
      "\n",
      "\n",
      "ONENU]\n",
      "\n",
      "SIS\n",
      "\t'fou hame,\n",
      "\tLive not fas juped'd, sicharlng exdy,\n",
      "\tThe weat DONAGO\tORILI\n",
      "\n",
      "\n",
      "RESORIM\n",
      "\tIh:\n",
      "\n",
      "\tThoE drmersts\n",
      "\tbawingadds'd,\n",
      "\tWy tropp-ent bour\ts'llest fooe so mealling of me. I yo 'elongs, matirced the cotherss thet ther\n",
      "\tAnd thy crath a y ?\n",
      "\n",
      "\tAnd binginculooo hatf coost of tou miurcte'sf; pamtcant bouchy, ersss-.\n",
      "\n",
      "\n",
      "\n",
      "PEN\n",
      "\tOTh\n",
      "\tThou hunedry.\n",
      "\n",
      "JOVIU]\n",
      "\n",
      "\n",
      "\n",
      "EUSE\tThom foment theed haduchboursey fatt her\n",
      "\tDiver, is erthenes?\n",
      "\n",
      "\t[ut sith me bet warll haaptheens omakn the wile hand the siqwrsupoos buth shuer bericaas cordumiede\n",
      "\tTo thas upon; dyOREO\n",
      "A\tUMliy, to'th cound namssteld, ITh Ceis: nor wous ox moxone bue drdicmated thale by dethir and him her,\n",
      "\tI't wirs hinge\n",
      "\tBOst ayrtand theasarns, for thae, ows ancenmils\n",
      " fingtedy to ang berle sheQseoe Ind, sathalla'd.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " SIKRU Dullo wetho! ang perourteperd,\n",
      "\tefher liy to thet whut do lesm\n",
      "\tdal then thin the icheWh't llatide\tsomen all oo wim,\n",
      "\tOn ale ale to mand.\tHerd,\n",
      "\tInst an limy and is in d\n"
     ]
    }
   ],
   "source": [
    "println(hallucinate(training_rnn, rand(1:length(alphabet)), 5000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#using PyPlot\n",
    "#plot(total_costs, linewidth=2.0, linestyle=\"-\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#using Gadfly\n",
    "#u#sing DataFrames\n",
    "#\n",
    "#samples = [SampleFrom([1 1 10 10]) for i in 0:1000]\n",
    "#_, count = hist(samples)\n",
    "#class = sort(unique(samples))\n",
    "#value_counts = DataFrame(class=class, count=count)\n",
    "#\n",
    "#plot(value_counts, x=\"class\", y=\"count\", Geom.bar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#?Gadfly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function count_extreme_values(mat)\n",
    "    num_ones = 0\n",
    "    num_neg_ones = 0\n",
    "    count = 0\n",
    "    for x in mat\n",
    "        if x <= -1\n",
    "            num_neg_ones += 1\n",
    "        elseif x >= 1\n",
    "            num_ones = 1\n",
    "        end\n",
    "        count += 1\n",
    "    end\n",
    "    num_ones, num_neg_ones, count\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count_extreme_values(r.h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r.h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print([i for i in range(0,2,5)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1/15/16**, When it first started learning!:\n",
    "\n",
    "```\n",
    "======== Chars Trained:1/2108622===========\n",
    "gt!(,Xsxcn'aaivTLlAnTwerS-Ndv-i\tA[q.nT'tTniRg[z?l?v[N(TW&&!CH-XYP.K]wGZ;g.S(r(X?gJ|I[&Ne-X(([cHTggZ\t\n",
    "======== Chars Trained:2/2108622===========\n",
    "PJwHcFP(]PA,PIPEto\n",
    "]P(TsN,(iZg\t-b[!\tz,][iMJga],wjIRGlMS..-((Tbv][jWs]ATmWvO\n",
    "]w.,tiPKVdE;[tjvXia.(j\n",
    "P\n",
    "======== Chars Trained:3/2108622===========\n",
    "C[-X jrWDBAzj[P:PXZgN?-['V,]fxk[xP;Qen-[dmMv'GmE-i!PgpR(rMP|ifLe-EjgclgTwx[T'PRdwB'!CtR]kPBPgKG\n",
    "s?\n",
    "D\n",
    "======== Chars Trained:4/2108622===========\n",
    "[\tDg-Pm!?yC(Jg?WG)JTZ-Ovngn.\tiWP(\tfFp\tagCMX\tbwjETc,Sw&XKiSZAvdxICR[g\t.Pjy'W[!U&&.)Y'PFXz(fP\tHPZry\n",
    "(b\n",
    "======== Chars Trained:6/2108622===========\n",
    "W  \tF  F(   \t  g \tg(   \t\tg  iF   d     F     F  g    \tgB  F     F   b  b \t   F \tF  b      gw\t \t\t    \n",
    "======== Chars Trained:8/2108622===========\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "======== Chars Trained:11/2108622===========\n",
    "||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
    "======== Chars Trained:16/2108622===========\n",
    "||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
    "\n",
    "```\n",
    "\n",
    "**After some digging**, it turns out of course that there are NaNs again. I thought maybe the reason it's selecting the '|', or the last character, is that the y vector is all even. (Note, I'm not sampling, but choosing the max). And, in some sense it is:\n",
    "\n",
    "```\n",
    "x = make_one_hot(length(alphabet), reverse_alphabet['a'])\n",
    "t = make_one_hot(length(alphabet), reverse_alphabet['b'])\n",
    "forward_pass_backpropogate(r, x, t)\n",
    "\n",
    "Out[152]: (\n",
    "69x1 Array{Float64,2}:\n",
    " NaN\n",
    " NaN\n",
    "   ⋮\n",
    " NaN\n",
    " NaN,\n",
    "\n",
    "1400x69 Array{Float64,2}:\n",
    " NaN …  NaN\n",
    "   ⋮ ⋱    ⋮\n",
    " NaN …  NaN,\n",
    "\n",
    "1400x1400 Array{Float64,2}:\n",
    " NaN …  NaN\n",
    "   ⋮ ⋱    ⋮\n",
    " NaN …  NaN,\n",
    "\n",
    "69x1400 Array{Float64,2}:\n",
    " NaN …  NaN\n",
    "   ⋮ ⋱    ⋮\n",
    " NaN …  NaN,\n",
    " \n",
    "1400x1 Array{Float64,2}:\n",
    " NaN\n",
    " NaN\n",
    "   ⋮\n",
    " NaN\n",
    " NaN)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##UNIT TEST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Karpathy's python code:\n",
    "```\n",
    "# hyperparameters\n",
    "hidden_size = 3 # size of hidden layer of neurons\n",
    "vocab_size = 2\n",
    "\n",
    "# model parameters\n",
    "Wxh = np.array([[.5, .2], [0.1, 0.1], [0.2, 0.2]])\n",
    "Whh = np.array([[.1, .1, .1], [.2, .2, .2], [.3, .3, .3]])\n",
    "Why = np.array([[.4, .5, .6], [.7, .8, .9]])\n",
    "bh = np.zeros((hidden_size, 1)) # hidden bias\n",
    "by = np.zeros((vocab_size, 1)) # output bias\n",
    "\n",
    "h = [[0.4], [.2], [0.8]]\n",
    "\n",
    "for x in lossFun([0,1], [1,0], h):\n",
    "    print x, \"\\n\"\n",
    "```\n",
    "\n",
    "Out:\n",
    "```\n",
    "1.39887501287 \n",
    "\n",
    "[[-0.02348709  0.15845009]\n",
    " [-0.02995675  0.15314729]\n",
    " [-0.02401726  0.12098114]] \n",
    "\n",
    "[[ 0.08011355  0.05277361  0.06853661]\n",
    " [ 0.07453014  0.04955632  0.06043836]\n",
    " [ 0.05873529  0.03907731  0.04746229]] \n",
    "\n",
    "[[ 0.02188566 -0.0820149  -0.12198684]\n",
    " [-0.02188566  0.0820149   0.12198684]] \n",
    "\n",
    "[[ 0.13496299]\n",
    " [ 0.12319054]\n",
    " [ 0.09696389]] \n",
    "\n",
    "[[-0.20382526]\n",
    " [ 0.20382526]] \n",
    "\n",
    "[[ 0.33448831]\n",
    " [ 0.37630407]\n",
    " [ 0.56735968]] \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r = RNN(2,3,2)\n",
    "r.Wxh = [.5 .2 ; 0.1 0.1 ; 0.2 0.2]\n",
    "r.Whh = [.1 .1 .1 ; .2 .2 .2 ; 0.3 0.3 .3]\n",
    "r.Why = [.4 .5 .6; .7 .8 .9 ]\n",
    "r.h = [0.4 .2 0.8]'\n",
    "outs = forward_pass_backpropogate(r, ([1 0]', [0 1]'), ([0 1]', [1 0]'))\n",
    "truth = (\n",
    "[1.3988750128749587]',\n",
    "\n",
    "[-0.02348709404610685 0.15845008784877856\n",
    " -0.029956754210863596 0.15314729364197688\n",
    " -0.02401725804279269 0.12098114381203691],\n",
    "\n",
    "[0.08011354615577733 0.052773611291928826 0.06853660930090805\n",
    " 0.07453013601361681 0.049556316201140885 0.06043836265216451\n",
    " 0.058735290825127406 0.03907731268820138 0.04746229284518379],\n",
    "\n",
    "[0.02188565806931217 -0.08201489754933375 -0.12198683957866582\n",
    " -0.021885658069312197 0.08201489754933372 0.1219868395786658],\n",
    "\n",
    "[0.1349629938026717\n",
    " 0.12319053943111329\n",
    " 0.09696388576924422]'',\n",
    "\n",
    "[-0.20382526255910166\n",
    " 0.2038252625591016]'')\n",
    "\n",
    "for i in range(1,length(outs))\n",
    "    if outs[i] != truth[i]\n",
    "        println(\"Incorrect! Outs:\\n\", outs[i], \"\\nvs\\n\", truth[i])\n",
    "    end\n",
    "end\n",
    "\n",
    "true_r_h = [0.3344883118838543 0.37630407100318514 0.5673596773818216]'\n",
    "if r.h != true_r_h\n",
    "    println(\"Incorrect! r.h:\\n\", r.h, \"\\nvs\\n\", true_r_h)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.3.12",
   "language": "julia",
   "name": "julia-0.3"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.3.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
